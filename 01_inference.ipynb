{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870610e8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ðŸš€ Install required packages for running the model\n",
    "# - transformers: for loading and running LLMs\n",
    "# - datasets: optional, for dataset handling\n",
    "# - peft: for later LoRA experiments\n",
    "# - accelerate: for optimized GPU usage in Colab\n",
    "!pip install -q transformers datasets peft accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263c4f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ðŸ” Check GPU availability in Colab\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU not available. Make sure Runtime -> Change runtime type -> GPU is selected\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
